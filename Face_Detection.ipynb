{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_SvpVSMfarx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/biubug6/Pytorch_Retinaface.git"
      ],
      "metadata": {
        "id": "f6mrUHkFfbEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python train.py --network mobile0.25 --training_dataset 'path_to_train_labels'"
      ],
      "metadata": {
        "id": "Qmp351TIf8xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from models.retinaface import RetinaFace\n",
        "from data import cfg_mnet, cfg_re50\n",
        "\n",
        "from layers.functions.prior_box import PriorBox\n",
        "from utils.nms.py_cpu_nms import py_cpu_nms\n",
        "from utils.box_utils import decode, decode_landm"
      ],
      "metadata": {
        "id": "ULGJPiwVfbGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_path = 'path_to_weight_file'\n",
        "cfg = cfg_mnet # mobile0.25 (cfg_mnet) or resnet50 (cfg_re50)\n",
        "resize = 1\n",
        "confidence_threshold = 0.02\n",
        "top_k = 5000\n",
        "nms_threshold = 0.4\n",
        "keep_top_k = 750\n",
        "vis_thres = 0.6"
      ],
      "metadata": {
        "id": "dnsrs31FfbI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cpu\"\n",
        "model = RetinaFace(cfg, phase = 'test').to(device)\n",
        "model.load_state_dict(torch.load(weight_path, map_location=device))\n",
        "model.eval()\n",
        "print(\"Model Loaded!\")"
      ],
      "metadata": {
        "id": "NMZ_07F0fbK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retinaface_inf(test_img, model):\n",
        "    # Convert image to numpy float32 format\n",
        "    img = np.float32(test_img)\n",
        "    im_height, im_width, _ = img.shape\n",
        "\n",
        "    # Define scale for image\n",
        "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
        "    # Subtract mean values from image\n",
        "    img -= (104, 117, 123)\n",
        "    # Transpose image to required format\n",
        "    img = img.transpose(2, 0, 1)\n",
        "    # Convert numpy array to torch tensor and add batch dimension\n",
        "    img = torch.from_numpy(img).unsqueeze(0)\n",
        "    # Move image and scale to device\n",
        "    img = img.to(device)\n",
        "    scale = scale.to(device)\n",
        "\n",
        "    tic = time.time()\n",
        "    # Perform forward pass through the model\n",
        "    loc, conf, landms = model(img)\n",
        "\n",
        "    # Calculate prior boxes\n",
        "    priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
        "    priors = priorbox.forward()\n",
        "    priors = priors.to(device)\n",
        "    prior_data = priors.data\n",
        "    # Decode predicted locations to bounding boxes\n",
        "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
        "    boxes = boxes * scale / resize\n",
        "    boxes = boxes.cpu().numpy()\n",
        "    # Extract confidence scores\n",
        "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
        "\n",
        "    # Ignore low confidence detections\n",
        "    inds = np.where(scores > confidence_threshold)[0]\n",
        "    boxes = boxes[inds]\n",
        "    scores = scores[inds]\n",
        "\n",
        "    # Keep top-K detections before Non-Maximum Suppression (NMS)\n",
        "    order = scores.argsort()[::-1][:top_k]\n",
        "    boxes = boxes[order]\n",
        "    scores = scores[order]\n",
        "\n",
        "    # Perform NMS\n",
        "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
        "    keep = py_cpu_nms(dets, nms_threshold)\n",
        "    dets = dets[keep, :]\n",
        "\n",
        "    # Keep top-K detections after NMS\n",
        "    dets = dets[:keep_top_k, :]\n",
        "\n",
        "    # Calculate frames per second (FPS)\n",
        "    fps_ = round(1/(time.time() - tic), 2)\n",
        "    # Draw bounding boxes on the image\n",
        "    for b in dets:\n",
        "        if b[4] < vis_thres:\n",
        "            continue\n",
        "        b = list(map(int, b))\n",
        "        cv2.rectangle(test_img, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 4)\n",
        "\n",
        "    # Define font properties\n",
        "    font_scale = 2\n",
        "    thickness = 3\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    # Add label \"Retinaface\" to the image\n",
        "    text = \"Retinaface\"\n",
        "    (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
        "    text_position = (im_width - text_width - 10, im_height - 20)\n",
        "    cv2.putText(test_img, text, text_position, font, font_scale, (0, 0, 255), thickness, cv2.LINE_AA)\n",
        "\n",
        "    # Add FPS information to the image\n",
        "    fps_text = \"FPS: \" + str(fps_)\n",
        "    (text_width, text_height), _ = cv2.getTextSize(fps_text, font, font_scale, thickness)\n",
        "    fps_position = (im_width - text_width - 10, im_height - 20 - text_height - 10)\n",
        "    cv2.putText(test_img, fps_text, fps_position, font, font_scale, (0, 0, 255), thickness, cv2.LINE_AA)\n",
        "\n",
        "    return test_img\n"
      ],
      "metadata": {
        "id": "jn9o5YyqfbNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = 'path_to_test_image'\n",
        "test_img = cv2.imread(test_path)\n",
        "\n",
        "retina_img = retinaface_inf(test_img, model)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tKthzJmKfbPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "# Initialize dlib's face detector\n",
        "face_detector = dlib.get_frontal_face_detector()"
      ],
      "metadata": {
        "id": "U0qXYbMPfbYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dlib_inf(test_img, face_detector):\n",
        "    # Convert image to numpy float32 format\n",
        "    img = np.float32(test_img)\n",
        "    im_height, im_width, _ = img.shape\n",
        "\n",
        "    tic = time.time()\n",
        "    # Perform face detection using dlib\n",
        "    face_detection = face_detector(test_img)\n",
        "    fps_ = round(1/(time.time() - tic), 2)\n",
        "    # Draw bounding boxes on the image\n",
        "    for f in face_detection:\n",
        "        cv2.rectangle(test_img, (f.left(), f.top()), (f.right(), f.bottom()), (255,0,0), 4)\n",
        "    # Define font properties\n",
        "    font_scale = 2\n",
        "    thickness = 3\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    # Add label \"Dlib\" to the image\n",
        "    text = \"Dlib\"\n",
        "    (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
        "    text_position = (im_width - text_width - 10, im_height - 20)\n",
        "    cv2.putText(test_img, text, text_position, font, font_scale, (255, 0, 0), thickness, cv2.LINE_AA)\n",
        "\n",
        "    # Add FPS information to the image\n",
        "    fps_text = \"FPS: \" + str(fps_)\n",
        "    (text_width, text_height), _ = cv2.getTextSize(fps_text, font, font_scale, thickness)\n",
        "    fps_position = (im_width - text_width - 10, im_height - 20 - text_height - 10)\n",
        "    cv2.putText(test_img, fps_text, fps_position, font, font_scale, (255, 0, 0), thickness, cv2.LINE_AA)\n",
        "\n",
        "    return test_img"
      ],
      "metadata": {
        "id": "kj8_REfOfbZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path ='path_to_test_image'\n",
        "test_img = cv2.imread(test_path)\n",
        "\n",
        "dlib_img = dlib_inf(test_img, face_detector)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L6bmThwyfbcU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}